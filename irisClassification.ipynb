{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np # lin alg\n",
    "import matplotlib.pyplot as plt # plot\n",
    "import pandas as pd # data input\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "data = pd.read_csv('IRIS.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue= 'species', height= 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the code for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, n_input, n_hidden, n_outputs, learning_rate):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_outputs = n_outputs\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights and biases with random values\n",
    "        self.weights = [np.random.randn(self.n_hidden, self.n_input),\n",
    "                        np.random.randn(self.n_outputs, self.n_hidden)]\n",
    "        \n",
    "        self.biases = [np.random.randn(self.n_hidden),\n",
    "                       np.random.randn(self.n_outputs)]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        x = np.clip(x, -500, 500)  # Clip input values to avoid overflow\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def dsigmoid(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def make_prediction(self, input_vector):\n",
    "        hidden_layer = self.sigmoid(np.dot(self.weights[0], input_vector) + self.biases[0])\n",
    "        output_layer = self.sigmoid(np.dot(self.weights[1], hidden_layer) + self.biases[1])\n",
    "        return output_layer\n",
    "\n",
    "    def gradient_descent(self, input_vector, target):\n",
    "        # Forward pass\n",
    "        hidden_layer = self.sigmoid(np.dot(self.weights[0], input_vector) + self.biases[0])\n",
    "        output_layer = self.sigmoid(np.dot(self.weights[1], hidden_layer) + self.biases[1])\n",
    "        \n",
    "        # Calculate error\n",
    "        error = output_layer - target\n",
    "        \n",
    "        # Backpropagation\n",
    "        derror_doutput = error * self.dsigmoid(output_layer)\n",
    "        doutput_dhidden = np.dot(self.weights[1].T, derror_doutput) * self.dsigmoid(hidden_layer)\n",
    "\n",
    "        # Calculate gradients\n",
    "        derror_dweights1 = np.outer(derror_doutput, hidden_layer)\n",
    "        derror_dbias1 = derror_doutput\n",
    "        derror_dweights0 = np.outer(doutput_dhidden, input_vector)\n",
    "        derror_dbias0 = doutput_dhidden\n",
    "\n",
    "        return [derror_dweights0, derror_dweights1], [derror_dbias0, derror_dbias1]\n",
    "\n",
    "    def update(self, gradients, biases):\n",
    "        self.weights[0] -= self.learning_rate * gradients[0]\n",
    "        self.weights[1] -= self.learning_rate * gradients[1]\n",
    "        self.biases[0] -= self.learning_rate * biases[0]\n",
    "        self.biases[1] -= self.learning_rate * biases[1]\n",
    "\n",
    "    def train(self, input_vectors, targets, iterations):\n",
    "        all_errors = []\n",
    "        for current_iteration in range(iterations):\n",
    "            # Pick a random data point\n",
    "            random_index = np.random.randint(len(input_vectors))\n",
    "            input_vector = input_vectors[random_index]\n",
    "            target = targets[random_index]\n",
    "\n",
    "            # Compute gradients using backpropagation\n",
    "            gradients, biases = self.gradient_descent(input_vector, target)\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.update(gradients, biases)\n",
    "\n",
    "            # Calculate cumulative error for monitoring\n",
    "            if current_iteration % 100 == 0:\n",
    "                cumulative_error = 0\n",
    "                for i in range(len(input_vectors)):\n",
    "                    data_point = input_vectors[i]\n",
    "                    target = targets[i]\n",
    "                    error = np.square(self.make_prediction(data_point) - target)\n",
    "                    cumulative_error += error\n",
    "                all_errors.append(np.sum(cumulative_error))\n",
    "\n",
    "        return all_errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
